{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /home/integration/test/new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/integration/test/new'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['samplehololensimage.jpg',\n",
       " 'percentage_50_text_encoder_florence2_attention_map_tensor.pt',\n",
       " 'florence_2_from_cloned_repo.ipynb',\n",
       " 'fan_percentage_50_vision_florence2_attention_map_tensor.pt',\n",
       " 'fan_percentage_50_text_decoder_florence2_attention_map_tensor.pt',\n",
       " 'percentage_50_text_decoder_florence2_attention_map_tensor.pt',\n",
       " 'trash_percentage_50_vision_florence2_attention_map_tensor.pt',\n",
       " 'Florence-2-large-ft',\n",
       " 'percentage_50_vision_florence2_attention_map_tensor.pt',\n",
       " 'fan_percentage_50_text_encoder_florence2_attention_map_tensor.pt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "\n",
    "# Path to your cloned repository\n",
    "local_model_path = \"./Florence-2-large-ft\"  # or full path like \"/path/to/Florence-2-large-ft\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# Load model from local path\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_model_path,\n",
    "    torch_dtype=torch_dtype,\n",
    "    trust_remote_code=True\n",
    ").to(device)\n",
    "\n",
    "# Load processor from local path\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    local_model_path,\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_example(image,task_prompt, text_input=None ,tensor_checkpoint_id=\"\"):\n",
    "    if text_input is None:\n",
    "        prompt = task_prompt\n",
    "    else:\n",
    "        prompt = task_prompt + text_input\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to('cuda', torch.float16)\n",
    "    \n",
    "    model.forward_pass_tensor_checkpoint_id = tensor_checkpoint_id\n",
    "    generated_ids = model.generate(\n",
    "      input_ids=inputs[\"input_ids\"].cuda(),\n",
    "      pixel_values=inputs[\"pixel_values\"].cuda(),\n",
    "      max_new_tokens=1024,\n",
    "      early_stopping=False,\n",
    "      do_sample=False,\n",
    "      num_beams=3,\n",
    "    )\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
    "    parsed_answer = processor.post_process_generation(\n",
    "        generated_text, \n",
    "        task=task_prompt, \n",
    "        image_size=(image.width, image.height)\n",
    "    )\n",
    "\n",
    "\n",
    "    return parsed_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hololens_image = Image.open('samplehololensimage.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Florence-2: vision 50% attention map saved\n",
      "Florence-2: text_encoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'<DETAILED_CAPTION>': 'In this image I can see a chair, a table fan, few bottles and few other objects on the table. I can also see a dustbin, a cardboard box, a plant and few glass windows. Through the windows we can see few trees, few buildings and the sky.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_prompt = '<DETAILED_CAPTION>'\n",
    "run_example(image=hololens_image, task_prompt=task_prompt, text_input=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Florence-2: vision 50% attention map saved\n",
      "Florence-2: text_encoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'': 'on shelf'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_prompt = ''\n",
    "run_example(image=hololens_image, task_prompt=task_prompt, text_input=\"Where is the fan?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Florence-2: vision 50% attention map saved\n",
      "Florence-2: text_encoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n",
      "Florence-2: text_decoder 50% attention map saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'': 'floor'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_prompt = ''\n",
    "run_example(image=hololens_image, task_prompt=task_prompt, text_input=\"Where is the trash can?\",tensor_checkpoint_id=\"trash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass for storing intermediate attention maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['samplehololensimage.jpg',\n",
       " 'percentage_50_text_encoder_florence2_attention_map_tensor.pt',\n",
       " 'florence_2_from_cloned_repo.ipynb',\n",
       " '_percentage_50_vision_florence2_attention_map_tensor.pt',\n",
       " '_percentage_50_text_encoder_florence2_attention_map_tensor.pt',\n",
       " 'fan_percentage_50_vision_florence2_attention_map_tensor.pt',\n",
       " 'fan_percentage_50_text_decoder_florence2_attention_map_tensor.pt',\n",
       " 'percentage_50_text_decoder_florence2_attention_map_tensor.pt',\n",
       " 'trash_percentage_50_vision_florence2_attention_map_tensor.pt',\n",
       " 'Florence-2-large-ft',\n",
       " '_percentage_50_text_decoder_florence2_attention_map_tensor.pt',\n",
       " 'percentage_50_vision_florence2_attention_map_tensor.pt',\n",
       " 'fan_percentage_50_text_encoder_florence2_attention_map_tensor.pt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the tensor \n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6540/2729667708.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tensor1 = torch.load('trash_percentage_50_text_encoder_florence2_attention_map_tensor.pt')\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.load('trash_percentage_50_text_encoder_florence2_attention_map_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 585, 1024])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sasika Pamith\n"
     ]
    }
   ],
   "source": [
    "model.sasika_pamith()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vision_tower': DaViT(\n",
       "   (convs): ModuleList(\n",
       "     (0): ConvEmbed(\n",
       "       (proj): Conv2d(3, 256, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "       (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "     (1): ConvEmbed(\n",
       "       (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "     (2): ConvEmbed(\n",
       "       (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "     (3): ConvEmbed(\n",
       "       (proj): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "       (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       "   (blocks): ModuleList(\n",
       "     (0): MySequential(\n",
       "       (0): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "               (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): Identity()\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): Identity()\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "               (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.004)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.004)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): MySequential(\n",
       "       (0): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.009)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.009)\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "               (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.013)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.013)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): MySequential(\n",
       "       (0): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.017)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.017)\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.022)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.022)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (1): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.026)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.026)\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.030)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.030)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (2): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.035)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.035)\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.039)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.039)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (3): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.043)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.043)\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.048)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.048)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (4): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.052)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.052)\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.057)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.057)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (5): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.061)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.061)\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.065)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.065)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (6): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.070)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.070)\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.074)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.074)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (7): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.078)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.078)\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.083)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.083)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (8): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.087)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.087)\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "               (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.091)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.091)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): MySequential(\n",
       "       (0): MySequential(\n",
       "         (spatial_block): SpatialBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "             )\n",
       "           )\n",
       "           (window_attn): PreNorm(\n",
       "             (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): WindowAttention(\n",
       "               (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "               (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "               (softmax): Softmax(dim=-1)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.096)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.096)\n",
       "           )\n",
       "         )\n",
       "         (channel_block): ChannelBlock(\n",
       "           (conv1): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "             )\n",
       "           )\n",
       "           (channel_attn): PreNorm(\n",
       "             (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): ChannelAttention(\n",
       "               (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "               (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.100)\n",
       "           )\n",
       "           (conv2): PreNorm(\n",
       "             (fn): DepthWiseConv2d(\n",
       "               (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "             )\n",
       "           )\n",
       "           (ffn): PreNorm(\n",
       "             (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "             (fn): Mlp(\n",
       "               (net): Sequential(\n",
       "                 (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                 (act): GELU(approximate='none')\n",
       "                 (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): DropPath(drop_prob=0.100)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       " ),\n",
       " 'image_proj_norm': LayerNorm((1024,), eps=1e-05, elementwise_affine=True),\n",
       " 'image_pos_embed': LearnedAbsolutePositionEmbedding2D(\n",
       "   (row_embeddings): Embedding(50, 1024)\n",
       "   (column_embeddings): Embedding(50, 1024)\n",
       " ),\n",
       " 'visual_temporal_embed': PositionalEmbeddingCosine1D(),\n",
       " 'language_model': Florence2LanguageForConditionalGeneration(\n",
       "   (model): Florence2LanguageModel(\n",
       "     (shared): Embedding(51289, 1024, padding_idx=1)\n",
       "     (encoder): Florence2Encoder(\n",
       "       (embed_tokens): Florence2ScaledWordEmbedding(51289, 1024, padding_idx=1)\n",
       "       (embed_positions): Florence2LearnedPositionalEmbedding(1026, 1024)\n",
       "       (layers): ModuleList(\n",
       "         (0-11): 12 x Florence2EncoderLayer(\n",
       "           (self_attn): Florence2SdpaAttention(\n",
       "             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           )\n",
       "           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (activation_fn): GELUActivation()\n",
       "           (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "           (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "           (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "       (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "     (decoder): Florence2Decoder(\n",
       "       (embed_tokens): Florence2ScaledWordEmbedding(51289, 1024, padding_idx=1)\n",
       "       (embed_positions): Florence2LearnedPositionalEmbedding(1026, 1024)\n",
       "       (layers): ModuleList(\n",
       "         (0-11): 12 x Florence2DecoderLayer(\n",
       "           (self_attn): Florence2SdpaAttention(\n",
       "             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           )\n",
       "           (activation_fn): GELUActivation()\n",
       "           (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (encoder_attn): Florence2SdpaAttention(\n",
       "             (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           )\n",
       "           (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "           (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "           (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "       (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       "   (lm_head): Linear(in_features=1024, out_features=51289, bias=False)\n",
       " )}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model._modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['vision_tower', 'image_proj_norm', 'image_pos_embed', 'visual_temporal_embed', 'language_model'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'lm_head'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Florence2LanguageModel(\n",
       "  (shared): Embedding(51289, 1024, padding_idx=1)\n",
       "  (encoder): Florence2Encoder(\n",
       "    (embed_tokens): Florence2ScaledWordEmbedding(51289, 1024, padding_idx=1)\n",
       "    (embed_positions): Florence2LearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x Florence2EncoderLayer(\n",
       "        (self_attn): Florence2SdpaAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Florence2Decoder(\n",
       "    (embed_tokens): Florence2ScaledWordEmbedding(51289, 1024, padding_idx=1)\n",
       "    (embed_positions): Florence2LearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x Florence2DecoderLayer(\n",
       "        (self_attn): Florence2SdpaAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): Florence2SdpaAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=51289, bias=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['lm_head']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['shared', 'encoder', 'decoder'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(51289, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['shared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Florence2Encoder(\n",
       "  (embed_tokens): Florence2ScaledWordEmbedding(51289, 1024, padding_idx=1)\n",
       "  (embed_positions): Florence2LearnedPositionalEmbedding(1026, 1024)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x Florence2EncoderLayer(\n",
       "      (self_attn): Florence2SdpaAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (activation_fn): GELUActivation()\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['encoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['embed_tokens', 'embed_positions', 'layers', 'layernorm_embedding'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['encoder']._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Florence2ScaledWordEmbedding(51289, 1024, padding_idx=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['encoder']._modules['embed_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Florence2LearnedPositionalEmbedding(1026, 1024)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['encoder']._modules['embed_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-11): 12 x Florence2EncoderLayer(\n",
       "    (self_attn): Florence2SdpaAttention(\n",
       "      (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (activation_fn): GELUActivation()\n",
       "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['encoder']._modules['layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0K\tCODE_OF_CONDUCT.md\n",
      "4.0K\tLICENSE\n",
      "16K\tREADME.md\n",
      "4.0K\tSECURITY.md\n",
      "4.0K\tSUPPORT.md\n",
      "4.0K\tconfig.json\n",
      "16K\tconfiguration_florence2.py\n",
      "4.0K\tcustom_utils.py\n",
      "4.0K\tgeneration_config.json\n",
      "128K\tmodeling_florence2.py\n",
      "4.0K\tpreprocessor_config.json\n",
      "48K\tprocessing_florence2.py\n",
      "1.5G\tpytorch_model.bin\n",
      "4.0K\ttensor_checkpoints\n",
      "1.3M\ttokenizer.json\n",
      "4.0K\ttokenizer_config.json\n",
      "1.1M\tvocab.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cd Florence-2-large-ft/ && du -sh *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['samplehololensimage.jpg',\n",
       " 'percentage_50_text_encoder_florence2_attention_map_tensor.pt',\n",
       " 'florence_2_from_cloned_repo.ipynb',\n",
       " '_percentage_50_vision_florence2_attention_map_tensor.pt',\n",
       " '_percentage_50_text_encoder_florence2_attention_map_tensor.pt',\n",
       " 'fan_percentage_50_vision_florence2_attention_map_tensor.pt',\n",
       " 'fan_percentage_50_text_decoder_florence2_attention_map_tensor.pt',\n",
       " 'percentage_50_text_decoder_florence2_attention_map_tensor.pt',\n",
       " 'trash_percentage_50_vision_florence2_attention_map_tensor.pt',\n",
       " 'Florence-2-large-ft',\n",
       " '_percentage_50_text_decoder_florence2_attention_map_tensor.pt',\n",
       " 'percentage_50_vision_florence2_attention_map_tensor.pt',\n",
       " 'fan_percentage_50_text_encoder_florence2_attention_map_tensor.pt']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Florence2LanguageModel(\n",
       "  (shared): Embedding(51289, 1024, padding_idx=1)\n",
       "  (encoder): Florence2Encoder(\n",
       "    (embed_tokens): Florence2ScaledWordEmbedding(51289, 1024, padding_idx=1)\n",
       "    (embed_positions): Florence2LearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x Florence2EncoderLayer(\n",
       "        (self_attn): Florence2SdpaAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation_fn): GELUActivation()\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Florence2Decoder(\n",
       "    (embed_tokens): Florence2ScaledWordEmbedding(51289, 1024, padding_idx=1)\n",
       "    (embed_positions): Florence2LearnedPositionalEmbedding(1026, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x Florence2DecoderLayer(\n",
       "        (self_attn): Florence2SdpaAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): Florence2SdpaAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-11): 12 x Florence2EncoderLayer(\n",
       "    (self_attn): Florence2SdpaAttention(\n",
       "      (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (activation_fn): GELUActivation()\n",
       "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['encoder']._modules['layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model._modules['language_model']._modules['model']._modules['encoder']._modules['layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_attn': Florence2SdpaAttention(\n",
       "   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       " ),\n",
       " 'self_attn_layer_norm': LayerNorm((1024,), eps=1e-05, elementwise_affine=True),\n",
       " 'activation_fn': GELUActivation(),\n",
       " 'fc1': Linear(in_features=1024, out_features=4096, bias=True),\n",
       " 'fc2': Linear(in_features=4096, out_features=1024, bias=True),\n",
       " 'final_layer_norm': LayerNorm((1024,), eps=1e-05, elementwise_affine=True)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['encoder']._modules['layers'][0]._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_attn': Florence2SdpaAttention(\n",
       "   (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       " ),\n",
       " 'self_attn_layer_norm': LayerNorm((1024,), eps=1e-05, elementwise_affine=True),\n",
       " 'activation_fn': GELUActivation(),\n",
       " 'fc1': Linear(in_features=1024, out_features=4096, bias=True),\n",
       " 'fc2': Linear(in_features=4096, out_features=1024, bias=True),\n",
       " 'final_layer_norm': LayerNorm((1024,), eps=1e-05, elementwise_affine=True)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['encoder']._modules['layers'][11]._modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['encoder']._modules['layernorm_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-11): 12 x Florence2DecoderLayer(\n",
       "    (self_attn): Florence2SdpaAttention(\n",
       "      (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (activation_fn): GELUActivation()\n",
       "    (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder_attn): Florence2SdpaAttention(\n",
       "      (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "    (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['decoder']._modules['layers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Florence2Decoder(\n",
       "  (embed_tokens): Florence2ScaledWordEmbedding(51289, 1024, padding_idx=1)\n",
       "  (embed_positions): Florence2LearnedPositionalEmbedding(1026, 1024)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x Florence2DecoderLayer(\n",
       "      (self_attn): Florence2SdpaAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (activation_fn): GELUActivation()\n",
       "      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (encoder_attn): Florence2SdpaAttention(\n",
       "        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['language_model']._modules['model']._modules['decoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DaViT(\n",
       "  (convs): ModuleList(\n",
       "    (0): ConvEmbed(\n",
       "      (proj): Conv2d(3, 256, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): ConvEmbed(\n",
       "      (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): ConvEmbed(\n",
       "      (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): ConvEmbed(\n",
       "      (proj): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): MySequential(\n",
       "      (0): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.004)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.004)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MySequential(\n",
       "      (0): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.009)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.009)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.013)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.013)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MySequential(\n",
       "      (0): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.017)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.017)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.022)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.022)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.026)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.026)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.030)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.030)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.035)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.035)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.039)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.039)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.043)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.043)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.048)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.048)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.052)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.052)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.057)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.057)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.061)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.061)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.065)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.065)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.070)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.070)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.074)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.074)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.078)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.078)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.083)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.083)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.087)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.087)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.091)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.091)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MySequential(\n",
       "      (0): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "              (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.096)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.096)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "              (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.100)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.100)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vision_tower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Vision Encoder breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DaViT(\n",
       "  (convs): ModuleList(\n",
       "    (0): ConvEmbed(\n",
       "      (proj): Conv2d(3, 256, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): ConvEmbed(\n",
       "      (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): ConvEmbed(\n",
       "      (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): ConvEmbed(\n",
       "      (proj): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): MySequential(\n",
       "      (0): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.004)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.004)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MySequential(\n",
       "      (0): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.009)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.009)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.013)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.013)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MySequential(\n",
       "      (0): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.017)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.017)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.022)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.022)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.026)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.026)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.030)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.030)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.035)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.035)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.039)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.039)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.043)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.043)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.048)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.048)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.052)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.052)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.057)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.057)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.061)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.061)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.065)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.065)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.070)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.070)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.074)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.074)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.078)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.078)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.083)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.083)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.087)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.087)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.091)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.091)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MySequential(\n",
       "      (0): MySequential(\n",
       "        (spatial_block): SpatialBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "          )\n",
       "          (window_attn): PreNorm(\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): WindowAttention(\n",
       "              (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "              (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.096)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.096)\n",
       "          )\n",
       "        )\n",
       "        (channel_block): ChannelBlock(\n",
       "          (conv1): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "          )\n",
       "          (channel_attn): PreNorm(\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): ChannelAttention(\n",
       "              (qkv): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "              (proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.100)\n",
       "          )\n",
       "          (conv2): PreNorm(\n",
       "            (fn): DepthWiseConv2d(\n",
       "              (dw): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
       "            )\n",
       "          )\n",
       "          (ffn): PreNorm(\n",
       "            (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (fn): Mlp(\n",
       "              (net): Sequential(\n",
       "                (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "                (act): GELU(approximate='none')\n",
       "                (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): DropPath(drop_prob=0.100)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['convs', 'blocks', 'avgpool'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): ConvEmbed(\n",
       "    (proj): Conv2d(3, 256, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (1): ConvEmbed(\n",
       "    (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (2): ConvEmbed(\n",
       "    (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (3): ConvEmbed(\n",
       "    (proj): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['convs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool1d(output_size=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['avgpool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model._modules['vision_tower']._modules['blocks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySequential(\n",
       "  (0): MySequential(\n",
       "    (spatial_block): SpatialBlock(\n",
       "      (conv1): PreNorm(\n",
       "        (fn): DepthWiseConv2d(\n",
       "          (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        )\n",
       "      )\n",
       "      (window_attn): PreNorm(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): WindowAttention(\n",
       "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (conv2): PreNorm(\n",
       "        (fn): DepthWiseConv2d(\n",
       "          (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        )\n",
       "      )\n",
       "      (ffn): PreNorm(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): Mlp(\n",
       "          (net): Sequential(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (channel_block): ChannelBlock(\n",
       "      (conv1): PreNorm(\n",
       "        (fn): DepthWiseConv2d(\n",
       "          (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        )\n",
       "      )\n",
       "      (channel_attn): PreNorm(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): ChannelAttention(\n",
       "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.004)\n",
       "      )\n",
       "      (conv2): PreNorm(\n",
       "        (fn): DepthWiseConv2d(\n",
       "          (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "        )\n",
       "      )\n",
       "      (ffn): PreNorm(\n",
       "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (fn): Mlp(\n",
       "          (net): Sequential(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.004)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][1]._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySequential(\n",
       "  (spatial_block): SpatialBlock(\n",
       "    (conv1): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      )\n",
       "    )\n",
       "    (window_attn): PreNorm(\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): WindowAttention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "    )\n",
       "    (conv2): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      )\n",
       "    )\n",
       "    (ffn): PreNorm(\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): Mlp(\n",
       "        (net): Sequential(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "    )\n",
       "  )\n",
       "  (channel_block): ChannelBlock(\n",
       "    (conv1): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      )\n",
       "    )\n",
       "    (channel_attn): PreNorm(\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): ChannelAttention(\n",
       "        (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (drop_path): DropPath(drop_prob=0.004)\n",
       "    )\n",
       "    (conv2): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "      )\n",
       "    )\n",
       "    (ffn): PreNorm(\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): Mlp(\n",
       "        (net): Sequential(\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_path): DropPath(drop_prob=0.004)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][0]._modules['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySequential(\n",
       "  (spatial_block): SpatialBlock(\n",
       "    (conv1): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "      )\n",
       "    )\n",
       "    (window_attn): PreNorm(\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): WindowAttention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (drop_path): DropPath(drop_prob=0.009)\n",
       "    )\n",
       "    (conv2): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "      )\n",
       "    )\n",
       "    (ffn): PreNorm(\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): Mlp(\n",
       "        (net): Sequential(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_path): DropPath(drop_prob=0.009)\n",
       "    )\n",
       "  )\n",
       "  (channel_block): ChannelBlock(\n",
       "    (conv1): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "      )\n",
       "    )\n",
       "    (channel_attn): PreNorm(\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): ChannelAttention(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (drop_path): DropPath(drop_prob=0.013)\n",
       "    )\n",
       "    (conv2): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "      )\n",
       "    )\n",
       "    (ffn): PreNorm(\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): Mlp(\n",
       "        (net): Sequential(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_path): DropPath(drop_prob=0.013)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][1]._modules['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySequential(\n",
       "  (spatial_block): SpatialBlock(\n",
       "    (conv1): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "      )\n",
       "    )\n",
       "    (window_attn): PreNorm(\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): WindowAttention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (drop_path): DropPath(drop_prob=0.017)\n",
       "    )\n",
       "    (conv2): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "      )\n",
       "    )\n",
       "    (ffn): PreNorm(\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): Mlp(\n",
       "        (net): Sequential(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_path): DropPath(drop_prob=0.017)\n",
       "    )\n",
       "  )\n",
       "  (channel_block): ChannelBlock(\n",
       "    (conv1): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "      )\n",
       "    )\n",
       "    (channel_attn): PreNorm(\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): ChannelAttention(\n",
       "        (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      )\n",
       "      (drop_path): DropPath(drop_prob=0.022)\n",
       "    )\n",
       "    (conv2): PreNorm(\n",
       "      (fn): DepthWiseConv2d(\n",
       "        (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "      )\n",
       "    )\n",
       "    (ffn): PreNorm(\n",
       "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (fn): Mlp(\n",
       "        (net): Sequential(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_path): DropPath(drop_prob=0.022)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['spatial_block', 'channel_block'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatialBlock(\n",
       "  (conv1): PreNorm(\n",
       "    (fn): DepthWiseConv2d(\n",
       "      (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "    )\n",
       "  )\n",
       "  (window_attn): PreNorm(\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (fn): WindowAttention(\n",
       "      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (drop_path): DropPath(drop_prob=0.017)\n",
       "  )\n",
       "  (conv2): PreNorm(\n",
       "    (fn): DepthWiseConv2d(\n",
       "      (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "    )\n",
       "  )\n",
       "  (ffn): PreNorm(\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (fn): Mlp(\n",
       "      (net): Sequential(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (drop_path): DropPath(drop_prob=0.017)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules['spatial_block']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv1', 'window_attn', 'conv2', 'ffn'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules['spatial_block']._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreNorm(\n",
       "  (fn): DepthWiseConv2d(\n",
       "    (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules['spatial_block']._modules['conv1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreNorm(\n",
       "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (fn): WindowAttention(\n",
       "    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (drop_path): DropPath(drop_prob=0.017)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules['spatial_block']._modules['window_attn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreNorm(\n",
       "  (fn): DepthWiseConv2d(\n",
       "    (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules['spatial_block']._modules['conv2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreNorm(\n",
       "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (fn): Mlp(\n",
       "    (net): Sequential(\n",
       "      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      (act): GELU(approximate='none')\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (drop_path): DropPath(drop_prob=0.017)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules['spatial_block']._modules['ffn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['norm', 'fn', 'drop_path'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules['spatial_block']._modules['window_attn']._modules.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules['spatial_block']._modules['window_attn']._modules['norm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowAttention(\n",
       "  (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "  (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules['spatial_block']._modules['window_attn']._modules['fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DropPath(drop_prob=0.017)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules['spatial_block']._modules['window_attn']._modules['drop_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChannelBlock(\n",
       "  (conv1): PreNorm(\n",
       "    (fn): DepthWiseConv2d(\n",
       "      (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "    )\n",
       "  )\n",
       "  (channel_attn): PreNorm(\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (fn): ChannelAttention(\n",
       "      (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "      (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (drop_path): DropPath(drop_prob=0.022)\n",
       "  )\n",
       "  (conv2): PreNorm(\n",
       "    (fn): DepthWiseConv2d(\n",
       "      (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "    )\n",
       "  )\n",
       "  (ffn): PreNorm(\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (fn): Mlp(\n",
       "      (net): Sequential(\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (drop_path): DropPath(drop_prob=0.022)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._modules['vision_tower']._modules['blocks'][2]._modules['0']._modules['channel_block']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
