{
  "os":  "Linux-6.5.0-28-generic-x86_64-with-glibc2.35",
  "python":  "CPython 3.11.10",
  "startedAt":  "2025-01-21T07:54:20.045636Z",
  "program":  "/home/integration/test/moondream_finetune_with_lora/4_finetune_moondream_std_adm_optim_jetson.py",
  "codePath":  "4_finetune_moondream_std_adm_optim_jetson.py",
  "git":  {
    "remote":  "git@github.com:test-a073/integration.git"
  },
  "email":  "sasikayw@smu.edu.sg",
  "root":  "/home/integration/test/moondream_finetune_with_lora",
  "host":  "6c196f619848",
  "executable":  "/opt/conda/bin/python3",
  "codePathLocal":  "4_finetune_moondream_std_adm_optim_jetson.py",
  "cpu_count":  20,
  "cpu_count_logical":  28,
  "gpu":  "NVIDIA RTX 6000 Ada Generation",
  "gpu_count":  1,
  "disk":  {
    "/":  {
      "total":  "954819596288",
      "used":  "855586729984"
    }
  },
  "memory":  {
    "total":  "67178819584"
  },
  "cpu":  {
    "count":  20,
    "countLogical":  28
  },
  "gpu_nvidia":  [
    {
      "name":  "NVIDIA RTX 6000 Ada Generation",
      "memoryTotal":  "48305799168",
      "cudaCores":  18176,
      "architecture":  "Ada"
    }
  ],
  "cudaVersion":  "12.4"
}